{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_lab_05.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eW6dySzs9_r1",
        "iPRKkkig9_r2",
        "XH1CSkRV9_r8",
        "B9Xivz3j9_sD",
        "rUeMEeHa9_sJ",
        "sWU9hWb_9_sO",
        "N8NnkvgF9_sR",
        "038JB6i49_sZ",
        "ST0oDfsq9_sk"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "254.39999389648438px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peX_6uD-ifG1"
      },
      "source": [
        "<img align=\"center\" style=\"max-width: 1000px\" src=\"https://github.com/HSG-AIML/LabAI-Coding/blob/main/resources/lab_05/banner.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0cP5Z789_rr"
      },
      "source": [
        "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"https://github.com/HSG-AIML/LabAI-Coding/blob/main/resources/lab_05/hsg_logo.png?raw=1\">\n",
        "\n",
        "##  Exam Exercise - \"Convolutional Neural Networks (CNNs)\" \n",
        "\n",
        "EMBA 58/59 - W8/3 - \"AI Coding for Executives\", University of St. Gallen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rno8GqfC9_rz"
      },
      "source": [
        "This week we have learned how to enhance vanilla Artificial Neural Networks (ANNs) using `PyTorch` to classify even more complex images. For this purpose, we used a special type of deep neural network referred to **Convolutional Neural Networks (CNNs)**. \n",
        "\n",
        "In our exam exercise, we aim to leverage that knowledge by applying it to the known Fashion-MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r93JK2DH9_r0"
      },
      "source": [
        "As always, pls. don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW6dySzs9_r1"
      },
      "source": [
        "## 1. Assignment Objectives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uzc9Xr69_r1"
      },
      "source": [
        "As discussed in our last session, these are the tasks for the exam exercise:\n",
        "\n",
        "> 1. Load the Fashion **MNIST dataset**. Implement a **CNN** architecture able to work with this data. **Train** your model.\n",
        "> 2. Evaluate your CNN **performance** and plot your results.\n",
        "> 3. Try to **improve** your initial model performance.\n",
        "> 4. **Document** your results in form of PowerPoint slides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPRKkkig9_r2"
      },
      "source": [
        "## 2. Setup of the Jupyter Notebook Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mZL4i6W9_r2"
      },
      "source": [
        "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mostly use the `PyTorch`, `Numpy`, `Sklearn`, `Matplotlib`, `Seaborn` and a few utility libraries throughout this lab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9cwWtab9_r2"
      },
      "source": [
        "# import standard python libraries\n",
        "import os, urllib, io\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrB_51t89_r3"
      },
      "source": [
        "Import Python machine / deep learning libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH6LhB_q9_r3"
      },
      "source": [
        "# import the PyTorch deep learning library\n",
        "import torch, torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfgYux7K9_r3"
      },
      "source": [
        "Import the sklearn classification metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFptYrnr9_r4"
      },
      "source": [
        "# import sklearn classification evaluation library\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJJ5kfaf9_r4"
      },
      "source": [
        "Import Python plotting libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usAgsocK9_r4"
      },
      "source": [
        "# import matplotlib, seaborn, and PIL data visualization libary\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZft6q1B9_r5"
      },
      "source": [
        "Enable notebook matplotlib inline plotting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXnX3zt_9_r5"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn2cf5SqJ2m9"
      },
      "source": [
        "Import Google's GDrive connector and mount your GDrive directories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2rj2ThhJ3sA"
      },
      "source": [
        "# import the Google Colab GDrive connector\n",
        "from google.colab import drive\n",
        "\n",
        "# mount GDrive inside the Colab notebook\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-58e-iazJ8Aq"
      },
      "source": [
        "Create a structure of Colab Notebook sub-directories inside of GDrive to store (1) the data as well as (2) the trained neural network models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtB6DCWjJ-gD"
      },
      "source": [
        "# create Colab Notebooks directory\n",
        "notebook_directory = '/content/drive/MyDrive/Colab Notebooks'\n",
        "if not os.path.exists(notebook_directory): os.makedirs(notebook_directory)\n",
        "\n",
        " # create data sub-directory inside the Colab Notebooks directory\n",
        "data_directory = '/content/drive/MyDrive/Colab Notebooks/data'\n",
        "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
        "\n",
        " # create models sub-directory inside the Colab Notebooks directory\n",
        "models_directory = '/content/drive/MyDrive/Colab Notebooks/models'\n",
        "if not os.path.exists(models_directory): os.makedirs(models_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcYgp4Gl9_r6"
      },
      "source": [
        "Set a random `seed` value to obtain reproducable results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdbqEjHb9_r7"
      },
      "source": [
        "# init deterministic seed\n",
        "seed_value = 1234\n",
        "np.random.seed(seed_value) # set numpy seed\n",
        "torch.manual_seed(seed_value) # set pytorch seed CPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpKQNDr09_r7"
      },
      "source": [
        "Google Colab provides the use of free GPUs for running notebooks. However, if you just execute this notebook as is, it will use your device's CPU. To run the lab on a GPU, got to `Runtime` > `Change runtime type` and set the Runtime type to `GPU` in the drop-down. Running this lab on a CPU is fine, but you will find that GPU computing is faster. *CUDA* indicates that the lab is being run on GPU.\n",
        "\n",
        "Enable GPU computing by setting the `device` flag and init a `CUDA` seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAFg7INc9_r7"
      },
      "source": [
        "# set cpu or gpu enabled device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
        "\n",
        "# init deterministic GPU seed\n",
        "torch.cuda.manual_seed(seed_value)\n",
        "\n",
        "# log type of device enabled\n",
        "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-7Ve4-_9_r7"
      },
      "source": [
        "Let's determine if we have access to a GPU provided by e.g. Google's COLab environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCpTB9x59_r8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mZNLbFQifHF"
      },
      "source": [
        "## 3. Exam Exercise: Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUd6ScWXmkel"
      },
      "source": [
        "The **Fashion-MNIST database** is a large database of Zalando articles that is commonly used for training various image processing systems. The database is widely used for training and testing in the field of machine learning. Source: https://www.kaggle.com/c/insar-fashion-mnist-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH1CSkRV9_r8"
      },
      "source": [
        "### 3.1 Fashion-MNIST Dataset Download and Data Assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd4O6PSzmBk-"
      },
      "source": [
        "#### Step 1. define \"train\" path ###############################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 2. define transformations and download the \"train\" dataset ############\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "\n",
        "\n",
        "#### Step 3. setup/define labels ################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "\n",
        "\n",
        "#### Step 4. define \"eval\" path ################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 5. define transformation and download the \"eval\" dataset #############\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Xivz3j9_sD"
      },
      "source": [
        "### 3.2 Convolutional Neural Network (CNN) Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nswYOXvk9_r0"
      },
      "source": [
        "<img align=\"center\" style=\"max-width: 900px\" src=\"https://github.com/HSG-AIML/LabAI-Coding/blob/main/resources/lab_05/classification.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgqmaa129_sZ"
      },
      "source": [
        "Please note this image of a CNN was defined for the CIFAR-10 dataset. Your Fashion-MNIST images have a different size.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn2Wu-JaoXyJ"
      },
      "source": [
        "**1. Implement and train your \"baseline\" CNN.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx4C87LF9_sZ"
      },
      "source": [
        "#### Step 1. define and init neural network architecture #############################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 2. define loss, training hyperparameters and dataloader ####################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 3. run model training ######################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 4. run model evaluation ####################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNBnGfwU9_sa"
      },
      "source": [
        "**2. Implement and train your \"improved\" CNN.**\n",
        "(\"improved\" simply refers to a better classification accuracy than your baseline model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-zirkqH9_sa"
      },
      "source": [
        "#### Step 1. define and init neural network architecture #############################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 2. define loss, training hyperparameters and dataloader ####################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 3. run model training ######################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************\n",
        "\n",
        "#### Step 4. run model evaluation ####################################################################################\n",
        "\n",
        "# ***************************************************\n",
        "# INSERT YOUR SOLUTION/CODE HERE\n",
        "# ***************************************************"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}