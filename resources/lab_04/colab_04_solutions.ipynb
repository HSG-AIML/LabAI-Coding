{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dojtwAh1Ww1B"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"hsg_logo.png\">\n",
    "\n",
    "##  Lab 04 - \"Artificial Neural Networks (ANNs)\" Assignments\n",
    "\n",
    "EMBA 58/59 - W8/3 - \"AI Coding for Executives\", University of St. Gallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR4Ywe2HWw1M"
   },
   "source": [
    "In the last lab we learned how to implement, train, and apply our first **Artificial Neural Network (ANN)** using a Python library named `PyTorch`. The `PyTorch` library is an open-source machine learning library for Python, used for a variety of applications such as image classification and natural language processing. In this lab, we aim to leverage that knowledge by applying it to a set of self-coding assignments. But before we do so let's start with a motivational video by NVIDIA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgQ_ksmaWw1N"
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# NVIDIA: \"The Deep Learning Revolution\"\n",
    "YouTubeVideo('Dy0hJWltsyE', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-9LY1AjWw1O"
   },
   "source": [
    "As always, pls. don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aut1dJXmWw1O"
   },
   "source": [
    "## 1. Assignment Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tb0svb4Ww1O"
   },
   "source": [
    "Similar today's lab session, after today's self-coding assignments you should be able to:\n",
    "\n",
    "> 1. Understand the basic concepts, intuitions and major building blocks of **Artificial Neural Networks (ANNs)**.\n",
    "> 2. Know how to use Python's **PyTorch library** to train and evaluate neural network based models.\n",
    "> 3. Understand how to apply neural networks to **classify images** of handwritten digits.\n",
    "> 4. Know how to **interpret the detection results** of the network as well as its **reconstruction loss**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks081EJEWw1P"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdmhjYHFWw1P"
   },
   "source": [
    "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mostly use the `PyTorch`, `Numpy`, `Sklearn`, `Matplotlib`, `Seaborn` and a few utility libraries throughout this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rDvIKj-Ww1P"
   },
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import os, urllib, io\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heUZY7dgWw1Q"
   },
   "source": [
    "Import the Python machine / deep learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RTb4Mc1Ww1Q"
   },
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning libary\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRpZfSImWw1R"
   },
   "source": [
    "Import the sklearn classification metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJ180J4sWw1R"
   },
   "outputs": [],
   "source": [
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tatoV81Ww1R"
   },
   "source": [
    "Import Python plotting libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTSNWwejWw1R"
   },
   "outputs": [],
   "source": [
    "# import matplotlib, seaborn, and PIL data visualization libary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g83bVkFrWw1S"
   },
   "source": [
    "Enable notebook matplotlib inline plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0MKI98CWw1S"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM3LiXwWWw1S"
   },
   "source": [
    "Import Google's GDrive connector and mount your GDrive directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptQU8CeEWw1S"
   },
   "outputs": [],
   "source": [
    "# import the Google Colab GDrive connector\n",
    "from google.colab import drive\n",
    "\n",
    "# mount GDrive inside the Colab notebook\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I81E5iJOwR6x"
   },
   "source": [
    "Create a structure of Colab Notebook sub-directories inside of GDrive to store (1) the data as well as (2) the trained neural network models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq5F-BV1wSXL"
   },
   "outputs": [],
   "source": [
    "# create Colab Notebooks directory\n",
    "notebook_directory = '/content/drive/MyDrive/Colab Notebooks'\n",
    "if not os.path.exists(notebook_directory): os.makedirs(notebook_directory)\n",
    "\n",
    " # create data sub-directory inside the Colab Notebooks directory\n",
    "data_directory = '/content/drive/MyDrive/Colab Notebooks/data'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
    "\n",
    " # create models sub-directory inside the Colab Notebooks directory\n",
    "models_directory = '/content/drive/MyDrive/Colab Notebooks/models'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32BCRqyA5cD5"
   },
   "source": [
    "Set a random `seed` value to obtain reproducable results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3cPTu1R5cmj"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHMs9Gf0wakv"
   },
   "source": [
    "Google Colab provides the use of free GPUs for running notebooks. However, if you just execute this notebook as is, it will use your device's CPU. To run the lab on a GPU, got to `Runtime` > `Change runtime type` and set the Runtime type to `GPU` in the drop-down. Running this lab on a CPU is fine, but you will find that GPU computing is faster. *CUDA* indicates that the lab is being run on GPU.\n",
    "\n",
    "Enable GPU computing by setting the device flag and init a CUDA seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl2UHzshwdyk"
   },
   "outputs": [],
   "source": [
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# init deterministic GPU seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled\n",
    "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47HnxJHswf05"
   },
   "source": [
    "Let's determine if we have access to a GPU provided by e.g. Google's COLab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "907R1nhVwhXb"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Artifcial Neural Networks (ANNs) Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyqnqndjWw1S"
   },
   "source": [
    "### 3.1 Fashion MNIST Dataset Download and Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgyKo34eWw1T"
   },
   "source": [
    "The **Fashion-MNIST database** is a large database of Zalando articles that is commonly used for training various image processing systems. The database is widely used for training and testing in the field of machine learning. Let's have a brief look into a couple of sample images contained in the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q9TexBXWw1T"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px; height: 300px\" src=\"FashionMNIST.png\">\n",
    "\n",
    "Source: https://www.kaggle.com/c/insar-fashion-mnist-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YEOHPO5Ww1T"
   },
   "source": [
    "Further details on the dataset can be obtained via Zalando research's [github page](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B6cw9iEWw1T"
   },
   "source": [
    "The **Fashion-MNIST database** is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando created this dataset with the intention of providing a replacement for the popular **MNIST** handwritten digits dataset. It is a useful addition as it is a bit more complex, but still very easy to use. It shares the same image size and train/test split structure as MNIST, and can therefore be used as a drop-in replacement. It requires minimal efforts on preprocessing and formatting the distinct images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igSTsQMKWw1U"
   },
   "source": [
    "Let's download, transform and inspect the training images of the dataset. Therefore, let's first define the directory in which we aim to store the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfCn1e8MWw1V"
   },
   "outputs": [],
   "source": [
    "train_path = data_directory + 'train_fashion_mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4fUsNeLWw1V"
   },
   "source": [
    "Now, let's download the training data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-GZL31YWw1W"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download and transform training images\n",
    "fashion_mnist_train_data = torchvision.datasets.FashionMNIST(root=train_path, train=True, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaLuUXc4Ww1W"
   },
   "source": [
    "Verify the number of training images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmRdyfxFWw1W"
   },
   "outputs": [],
   "source": [
    "# determine the number of training data images\n",
    "len(fashion_mnist_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctD4Dl0C_7RE"
   },
   "source": [
    "Next, we need to map each numerical label to its fashion item, which will be useful throughout the lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmzSMz1FASrm"
   },
   "outputs": [],
   "source": [
    "fashion_classes = {0: 'T-shirt/top',\n",
    "                    1: 'Trouser',\n",
    "                    2: 'Pullover',\n",
    "                    3: 'Dress',\n",
    "                    4: 'Coat',\n",
    "                    5: 'Sandal',\n",
    "                    6: 'Shirt',\n",
    "                    7: 'Sneaker',\n",
    "                    8: 'Bag',\n",
    "                    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5fmhiuzWw1Y"
   },
   "source": [
    "Let's now define the directory in which we aim to store the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8G3eQFy3Ww1b"
   },
   "outputs": [],
   "source": [
    "eval_path = data_directory + '/eval_fashion_mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNNTmyI7Ww1b"
   },
   "source": [
    "And download the evaluation data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvIBdhlPWw1b"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download and transform training images\n",
    "fashion_mnist_eval_data = torchvision.datasets.FashionMNIST(root=eval_path, train=False, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4skfCFEfWw1c"
   },
   "source": [
    "Let's also verify the number of evaluation images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq3rW2wKWw1c"
   },
   "outputs": [],
   "source": [
    "# determine the number of evaluation data images\n",
    "len(fashion_mnist_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucTxc7GGWw1c"
   },
   "source": [
    "### 3.2 Artificial Neural Network (ANN) Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i5LlBmiWw1d"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend you to try the following exercises as part of the self-coding session:\n",
    "\n",
    "**Exercise 1: Train the neural network architecture of the lab for less epochs and evaluate its prediction accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decrease the number of training epochs to **5 epochs** and re-run the network training. Load and evaluate the model exhibiting the lowest training loss. What kind of behaviour in terms of prediction accuracy can be observed with decreasing the number of training epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "#### Step 1. define and init neural network architecture #############################################################\n",
    "\n",
    "# implement the MNISTNet network architecture\n",
    "class FashionMNISTNet(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call super class constructor\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        \n",
    "        # specify fully-connected (fc) layer 1 - in 28*28, out 100\n",
    "        self.linear1 = nn.Linear(28*28, 100, bias=True) # the linearity W*x+b\n",
    "        self.relu1 = nn.ReLU(inplace=True) # the non-linearity \n",
    "        \n",
    "        # specify fc layer 2 - in 100, out 50\n",
    "        self.linear2 = nn.Linear(100, 50, bias=True) # the linearity W*x+b\n",
    "        self.relu2 = nn.ReLU(inplace=True) # the non-linarity\n",
    "        \n",
    "        # specify fc layer 3 - in 50, out 10\n",
    "        self.linear3 = nn.Linear(50, 10) # the linearity W*x+b\n",
    "        \n",
    "        # add a softmax to the last layer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # the softmax\n",
    "        \n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # reshape image pixels\n",
    "        x = images.view(-1, 28*28)\n",
    "        \n",
    "        # define fc layer 1 forward pass\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        \n",
    "        # define fc layer 2 forward pass\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        \n",
    "        # define layer 3 forward pass\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x\n",
    "\n",
    "# init the neural network model\n",
    "model = FashionMNISTNet()\n",
    "    \n",
    "#### Step 2. define loss, training hyperparameters and dataloader ####################################################\n",
    "    \n",
    "# define the optimization criterion / loss function\n",
    "nll_loss = nn.NLLLoss()\n",
    "\n",
    "# specify the training parameters\n",
    "num_epochs = 5 # number of training epochs\n",
    "mini_batch_size = 128 # size of the mini-batches\n",
    "\n",
    "# define learning rate and optimization strategy\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# init the training data loader\n",
    "fashion_mnist_train_dataloader = torch.utils.data.DataLoader(fashion_mnist_train_data, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "#### 3. run model training ###########################################################################################\n",
    "\n",
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the MNISTNet model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(fashion_mnist_train_dataloader):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = model(images)\n",
    "        \n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = nll_loss(output, labels)\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # save model to local directory\n",
    "    model_name = 'fashion_mnist_model_epoch_{}.pth'.format(str(epoch))\n",
    "    torch.save(model.state_dict(), os.path.join(\"./models\", model_name))\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "    \n",
    "#### 4. run model evaluation ########################################################################################\n",
    "\n",
    "# determine model predictions\n",
    "predictions = torch.argmax(model(fashion_mnist_eval_data.data.float()), dim=1)\n",
    "\n",
    "# determine accuracy scores\n",
    "metrics.accuracy_score(fashion_mnist_eval_data.targets, predictions.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2: Evaluation of \"shallow\" vs. \"deep\" neural network architectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In addition to the architecture of the lab notebook, evaluate further (more **shallow** as well as more **deep**) neural network architectures by (1) either **removing or adding** layers to the network and/or (2) increasing/decreasing the number of neurons per layer. Train a model (using the architectures you selected) for at least **20 training epochs**. Analyze the prediction performance of the trained models in terms of training time and prediction accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "#### Step 1. define and init neural network architecture #############################################################\n",
    "\n",
    "# implement the MNISTNet network architecture\n",
    "class FashionMNISTNet(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call super class constructor\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        \n",
    "        # specify fully-connected (fc) layer 1 - in 28*28, out 100\n",
    "        self.linear1 = nn.Linear(28*28, 100, bias=True) # the linearity W*x+b\n",
    "        self.relu1 = nn.ReLU(inplace=True) # the non-linearity \n",
    "        \n",
    "        # specify fc layer 2 - in 100, out 50\n",
    "        # self.linear2 = nn.Linear(100, 50, bias=True) # the linearity W*x+b\n",
    "        # self.relu2 = nn.ReLU(inplace=True) # the non-linarity\n",
    "        \n",
    "        # specify fc layer 3 - in 50, out 10\n",
    "        self.linear3 = nn.Linear(100, 10) # the linearity W*x+b\n",
    "        \n",
    "        # add a softmax to the last layer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # the softmax\n",
    "        \n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # reshape image pixels\n",
    "        x = images.view(-1, 28*28)\n",
    "        \n",
    "        # define fc layer 1 forward pass\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        \n",
    "        # define fc layer 2 forward pass\n",
    "        # x = self.relu2(self.linear2(x))\n",
    "        \n",
    "        # define layer 3 forward pass\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x\n",
    "\n",
    "# init the neural network model\n",
    "model = FashionMNISTNet()\n",
    "    \n",
    "#### Step 2. define loss, training hyperparameters and dataloader ####################################################\n",
    "    \n",
    "# define the optimization criterion / loss function\n",
    "nll_loss = nn.NLLLoss()\n",
    "\n",
    "# specify the training parameters\n",
    "num_epochs = 20 # number of training epochs\n",
    "mini_batch_size = 128 # size of the mini-batches\n",
    "\n",
    "# define learning rate and optimization strategy\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# init the training data loader\n",
    "fashion_mnist_train_dataloader = torch.utils.data.DataLoader(fashion_mnist_train_data, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "#### 3. run model training ###########################################################################################\n",
    "\n",
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the MNISTNet model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(fashion_mnist_train_dataloader):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = model(images)\n",
    "        \n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = nll_loss(output, labels)\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # set filename of actual model\n",
    "    model_name = 'fashion_mnist_model_epoch_{}.pth'.format(str(epoch))\n",
    "\n",
    "    # save current model to GDrive models directory\n",
    "    torch.save(model.state_dict(), os.path.join(models_directory, model_name))\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "    \n",
    "#### 4. run model evaluation #########################################################################################\n",
    "\n",
    "# determine model predictions\n",
    "predictions = torch.argmax(model(fashion_mnist_eval_data.data.float()), dim=1)\n",
    "\n",
    "# determine accuracy scores\n",
    "metrics.accuracy_score(fashion_mnist_eval_data.targets, predictions.detach())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aut1dJXmWw1O",
    "Ks081EJEWw1P",
    "vyqnqndjWw1S",
    "ucTxc7GGWw1c",
    "hJhKTaHnWw1i",
    "8nyWq1X-Ww1n",
    "DGnafHqlWw1u",
    "e1l8HbUzWw1v"
   ],
   "name": "ml_lab_04.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
