{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0cP5Z789_rr"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"hsg_logo.png\">\n",
    "\n",
    "##  Lab 05 - \"Convolutional Neural Networks (CNNs)\" Assignments\n",
    "\n",
    "EMBA 58/59 - W8/3 - \"AI Coding for Executives\", University of St. Gallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rno8GqfC9_rz"
   },
   "source": [
    "In the last lab we learned how to enhance vanilla Artificial Neural Networks (ANNs) using `PyTorch` to classify even more complex images. Therefore, we used a special type of deep neural network referred to **Convolutional Neural Networks (CNNs)**. CNNs encompass the ability to take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. In this lab, we aim to leverage that knowledge by applying it to a set of self-coding assignments. But before we do so let's start with another motivational video by NVIDIA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# NVIDIA: \"Official Intro | GTC 2020 | I AM AI\"\n",
    "YouTubeVideo('e2_hsjpTi4w', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r93JK2DH9_r0"
   },
   "source": [
    "As always, pls. don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW6dySzs9_r1"
   },
   "source": [
    "## 1. Assignment Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uzc9Xr69_r1"
   },
   "source": [
    "Similar today's lab session, after today's self-coding assignments you should be able to:\n",
    "\n",
    "> 1. Understand the basic concepts, intuitions and major building blocks of **Convolutional Neural Networks (CNNs)**.\n",
    "> 2. Know how to **implement and to train a CNN** to learn a model of tiny image data.\n",
    "> 3. Understand how to apply such a learned model to **classify images** images based on their content into distinct categories.\n",
    "> 4. Know how to **interpret and visualize** the model's classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPRKkkig9_r2"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mZL4i6W9_r2"
   },
   "source": [
    "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mostly use the `PyTorch`, `Numpy`, `Sklearn`, `Matplotlib`, `Seaborn` and a few utility libraries throughout this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9cwWtab9_r2"
   },
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import os, urllib, io\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrB_51t89_r3"
   },
   "source": [
    "Import Python machine / deep learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZH6LhB_q9_r3"
   },
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning library\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfgYux7K9_r3"
   },
   "source": [
    "Import the sklearn classification metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFptYrnr9_r4"
   },
   "outputs": [],
   "source": [
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJJ5kfaf9_r4"
   },
   "source": [
    "Import Python plotting libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usAgsocK9_r4"
   },
   "outputs": [],
   "source": [
    "# import matplotlib, seaborn, and PIL data visualization libary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZft6q1B9_r5"
   },
   "source": [
    "Enable notebook matplotlib inline plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXnX3zt_9_r5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfE3I18r9_r5"
   },
   "source": [
    "Create notebook folder structure to store the data as well as the trained neural network models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMFO6m7k9_r6"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./data'): os.makedirs('./data')  # create data directory\n",
    "if not os.path.exists('./models'): os.makedirs('./models')  # create trained models directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcYgp4Gl9_r6"
   },
   "source": [
    "Set a random `seed` value to obtain reproducable results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdbqEjHb9_r7"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convolutional Neural Networks (CNNs) Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XH1CSkRV9_r8"
   },
   "source": [
    "### 3.1 CIFAR-10 Dataset Download and Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWDn7IQE9_r8"
   },
   "source": [
    "The **CIFAR-10 database** (**C**anadian **I**nstitute **F**or **A**dvanced **R**esearch) is a collection of images that are commonly used to train machine learning and computer vision algorithms. The database is widely used to conduct computer vision research using machine learning and deep learning methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awuRyFMd9_r8"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 500px; height: 500px\" src=\"cifar10.png\">\n",
    "\n",
    "(Source: https://www.kaggle.com/c/cifar-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjdI5VVN9_r8"
   },
   "source": [
    "Further details on the dataset can be obtained via: *Krizhevsky, A., 2009. \"Learning Multiple Layers of Features from Tiny Images\",  \n",
    "( https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf ).\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaD13bmO9_r9"
   },
   "source": [
    "The CIFAR-10 database contains **60,000 color images** (50,000 training images and 10,000 validation images). The size of each image is 32 by 32 pixels. The collection of images encompasses 10 different classes that represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. Let's define the distinct classs for further analytics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WlB2yXu9_r-"
   },
   "outputs": [],
   "source": [
    "cifar10_classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRslZNGV9_r-"
   },
   "source": [
    "Thereby the dataset contains 6,000 images for each of the ten classes. The CIFAR-10 is a straightforward dataset that can be used to teach a computer how to recognize objects in images.\n",
    "\n",
    "Let's download, transform and inspect the training images of the dataset. Therefore, we first will define the directory we aim to store the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2Bmhc-c9_r-"
   },
   "outputs": [],
   "source": [
    "train_path = './data/train_cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6AGBP_K9_r_"
   },
   "source": [
    "Now, let's download the training data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_-Zs4EU9_sA"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and transform training images\n",
    "cifar10_train_data = torchvision.datasets.CIFAR10(root=train_path, train=True, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g79sdHOw9_sA"
   },
   "source": [
    "Verify the volume of training images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiKFBLrI9_sA"
   },
   "outputs": [],
   "source": [
    "# get the length of the training data\n",
    "len(cifar10_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWcoDhr_9_sC"
   },
   "source": [
    "Let's now decide on where we want to store the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKFBcveC9_sC"
   },
   "outputs": [],
   "source": [
    "eval_path = './data/eval_cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB5OpV4z9_sC"
   },
   "source": [
    "And download the evaluation data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-OOVFFs9_sD"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and transform validation images\n",
    "cifar10_eval_data = torchvision.datasets.CIFAR10(root=eval_path, train=False, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF4VrcHG9_sD"
   },
   "source": [
    "Let's also verfify the volume of validation images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhZRDL4X9_sD"
   },
   "outputs": [],
   "source": [
    "# get the length of the training data\n",
    "len(cifar10_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9Xivz3j9_sD"
   },
   "source": [
    "### 3.2 Convolutional Neural Network (CNN) Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nswYOXvk9_r0"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px\" src=\"classification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tgqmaa129_sZ"
   },
   "source": [
    "We recommend you to try the following exercises as part of the self-coding session:\n",
    "\n",
    "**Exercise 1: Train the neural network architecture of the lab a couple more epochs and evaluate its prediction accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Increase the number of training epochs up to 50 epochs and re-run the network training. Load and evaluate the model exhibiting the lowest training loss. What kind of behavior in terms of prediction accuracy can be observed with increasing the training epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx4C87LF9_sZ"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNBnGfwU9_sa"
   },
   "source": [
    "**2. Evaluation of \"shallow\" vs. \"deep\" neural network architectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In addition to the architecture of the lab notebook, evaluate further (more **shallow** as well as more **deep**) neural network architectures by (1) either **removing or adding** layers to the network and/or (2) increasing/decreasing the number of neurons per layer. Train a model (using the architectures you selected) for at least **50 training epochs**. Analyze the prediction performance of the trained models in terms of training time and prediction accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-zirkqH9_sa"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "eW6dySzs9_r1",
    "iPRKkkig9_r2",
    "XH1CSkRV9_r8",
    "B9Xivz3j9_sD",
    "rUeMEeHa9_sJ",
    "sWU9hWb_9_sO",
    "N8NnkvgF9_sR",
    "038JB6i49_sZ",
    "ST0oDfsq9_sk"
   ],
   "name": "ml_lab_05.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.39999389648438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
